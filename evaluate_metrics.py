import os
import re
import argparse
from collections import Counter
import numpy as np
from sklearn.metrics import jaccard_score
import nltk
from nltk.tokenize import sent_tokenize
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
# Bỏ import openai, thêm import google.generativeai
import google.generativeai as genai

# Thêm import từ project của bạn
# Giả định rằng bạn chạy script này từ thư mục gốc của project
# Ví dụ: python evaluate_metrics.py ...
from src_bot..service import bot_service_instance
from src_bot..bot import bot_instance

# Tải tài nguyên cho NLTK (chỉ cần chạy lần đầu)
try:
    nltk.data.find('tokenizers/punkt')
except nltk.downloader.DownloadError:
    nltk.download('punkt')

# --- CONFIGURATION ---
# Cấu hình API Key cho Google Gemini
# Nên đặt trong biến môi trường để bảo mật
# export GOOGLE_API_KEY='your_google_api_key'
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))

# --- CÁC HÀM TÍNH METRIC (GIỮ NGUYÊN) ---

def calculate_linter_overlap(ai_flagged_lines: set, sonarqube_flagged_lines: set) -> dict:
    """
    So sánh các dòng lỗi được phát hiện bởi AI và SonarQube.
    Sử dụng Jaccard Score (Intersection over Union).
    """
    if not ai_flagged_lines and not sonarqube_flagged_lines:
        return {"jaccard_score": 1.0, "intersection_count": 0, "union_count": 0}
    
    intersection = len(ai_flagged_lines.intersection(sonarqube_flagged_lines))
    union = len(ai_flagged_lines.union(sonarqube_flagged_lines))
    
    jaccard = intersection / union if union > 0 else 0.0
    
    return {
        "jaccard_score": jaccard,
        "intersection_count": intersection,
        "union_count": union
    }

# THAY THẾ HÀM GPT-4 BẰNG GEMINI
def get_gemini_judge_score(ai_review: str, code_context: str) -> dict:
    """
    Sử dụng Gemini 1.5 Pro để đánh giá chất lượng của review.
    """
    if not os.getenv("GOOGLE_API_KEY"):
        return {"score": -1, "justification": "Google API key not configured."}

    model = genai.GenerativeModel('gemini-1.5-pro-latest')
    
    prompt = f"""
    You are an expert software engineering manager acting as an impartial judge.
    Your task is to evaluate the quality of a code review comment generated by an AI assistant.

    **Code Context:**
    ```java
    {code_context}
    ```

    **AI's Review Comment:**
    "{ai_review}"

    **Evaluation Criteria:**
    1.  **Accuracy:** Is the comment correct? Does it identify a real issue?
    2.  **Relevance:** Is the issue significant, or is it a minor nitpick?
    3.  **Clarity:** Is the comment easy to understand?
    4.  **Actionability:** Does the comment provide a clear, actionable suggestion for improvement?

    Based on these criteria, please provide a score from 1 to 10 (1=Very Poor, 10=Excellent) and a brief justification for your score.
    Format your response as: "Score: [score]\nJustification: [justification]"
    """
    try:
        response = model.generate_content(prompt)
        response_text = response.text
        
        score_match = re.search(r"Score: (\d+\.?\d*)", response_text)
        justification_match = re.search(r"Justification: (.*)", response_text, re.DOTALL)
        
        score = float(score_match.group(1)) if score_match else -1
        justification = justification_match.group(1).strip() if justification_match else "Could not parse justification."
        
        return {"score": score, "justification": justification}

    except Exception as e:
        return {"score": -1, "justification": f"API call failed: {e}"}

def calculate_repetition_rate(ai_review: str) -> float:
    """
    Tính toán tỷ lệ lặp lại câu trong review.
    """
    sentences = sent_tokenize(ai_review.lower())
    if len(sentences) <= 1:
        return 0.0
    
    num_unique_sentences = len(set(sentences))
    repetition_rate = 1 - (num_unique_sentences / len(sentences))
    return repetition_rate

def check_hallucination(ai_review: str, code_context: str) -> dict:
    """
    Kiểm tra xem review có đề cập đến các biến/hàm không tồn tại trong code không.
    Đây là một phương pháp đơn giản, có thể cần cải tiến.
    """
    # Trích xuất các tên biến/hàm từ code (đơn giản hóa)
    code_identifiers = set(re.findall(r'\b([a-zA-Z_][a-zA-Z0-9_]{2,})\b', code_context))
    
    # Trích xuất các thực thể được đề cập trong review (thường trong dấu `...`)
    review_mentions = set(re.findall(r'`([^`]+)`', ai_review))
    
    if not review_mentions:
        return {"hallucination_rate": 0.0, "hallucinated_items": []}
        
    hallucinated_items = [item for item in review_mentions if item not in code_identifiers]
    
    hallucination_rate = len(hallucinated_items) / len(review_mentions)
    
    return {
        "hallucination_rate": hallucination_rate,
        "hallucinated_items": hallucinated_items
    }

class ToxicityClassifier:
    def __init__(self, model_name="unitary/toxic-bert"):
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            self.model.to(self.device)
            print(f"ToxicityClassifier loaded on {self.device}")
        except Exception as e:
            print(f"Failed to load model {model_name}: {e}")
            self.model = None

    def get_toxic_score(self, text: str) -> dict:
        if not self.model:
            return {"error": "Model not loaded."}
        
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=512).to(self.device)
        with torch.no_grad():
            logits = self.model(**inputs).logits
        
        probabilities = torch.sigmoid(logits).cpu().numpy()[0]
        
        # Lấy nhãn từ config của model
        labels = self.model.config.id2label
        
        scores = {labels[i]: prob for i, prob in enumerate(probabilities)}
        # Trả về điểm toxic cao nhất trong các loại
        toxic_score = scores.get('toxic', 0.0)

        return {"toxic_score": float(toxic_score), "all_scores": scores}


# --- HÀM LẤY DỮ LIỆU ---

def get_sonarqube_results(repo_name: str, pr_number: int) -> set:
    """
    HÀM GIẢ LẬP: Lấy kết quả từ SonarQube.
    BẠN CẦN THAY THẾ HÀM NÀY bằng logic thực tế để gọi API của SonarQube
    và trả về một set các số dòng bị gắn cờ.
    """
    print("--- [GIẢ LẬP] Lấy kết quả từ SonarQube... ---")
    # Ví dụ: trả về một lỗi giả định ở dòng 8
    return {8}

def extract_flagged_lines_from_review(ai_review: str) -> set:
    """
    Trích xuất các số dòng được đề cập trong review của AI.
    Ví dụ: "lỗi ở dòng 8" -> {8}
    """
    # Regex này tìm các số theo sau các từ như 'line', 'dòng', etc.
    found_lines = re.findall(r'(?:line|dòng)\s+(\d+)', ai_review, re.IGNORECASE)
    return set(map(int, found_lines))

# --- MAIN EXECUTION ---

def main(repo_name: str, pr_number: int):
    """
    Hàm chính để chạy toàn bộ quy trình đánh giá cho một Pull Request.
    """
    print(f"\n{'='*20} Bắt đầu đánh giá cho PR #{pr_number} trên repo {repo_name} {'='*20}")

    # 1. Lấy thông tin PR và file thay đổi từ GitHub
    print("\n[1/5] Đang lấy thông tin file từ Pull Request...")
    try:
        pr = bot_service_instance.get_pr(repo_name, pr_number)
        changed_files = bot_service_instance.get_pr_files(pr)
        if not changed_files:
            print("Không tìm thấy file thay đổi nào trong PR.")
            return
    except Exception as e:
        print(f"Lỗi khi lấy thông tin PR: {e}")
        return

    # 2. Chạy AI review trên các file thay đổi
    print("\n[2/5] Đang tạo review từ AI...")
    # Ghép tất cả nội dung file lại để tạo context và review
    full_code_context = ""
    ai_review_full = ""
    for file in changed_files:
        if file.patch is None:
            continue
        
        print(f"  - Đang review file: {file.filename}")
        full_code_context += f"--- File: {file.filename} ---\n{file.patch}\n\n"
        
        # Gọi bot để review từng file
        review_for_file = bot_instance.review(file.patch)
        ai_review_full += f"### Review cho file `{file.filename}`:\n{review_for_file}\n\n"

    if not ai_review_full:
        print("AI không tạo ra review nào.")
        return
        
    print("--- Review của AI ---")
    print(ai_review_full)
    print("--------------------")

    # 3. Lấy kết quả từ các nguồn "ground truth"
    print("\n[3/5] Đang lấy dữ liệu ground truth...")
    sonarqube_lines = get_sonarqube_results(repo_name, pr_number)
    ai_flagged_lines = extract_flagged_lines_from_review(ai_review_full)
    
    print(f"  - SonarQube flagged lines: {sonarqube_lines}")
    print(f"  - AI flagged lines: {ai_flagged_lines}")

    # 4. Khởi tạo các công cụ đánh giá
    print("\n[4/5] Đang khởi tạo các model đánh giá...")
    toxicity_classifier = ToxicityClassifier()

    # 5. Tính toán và in ra các metrics
    print("\n[5/5] Đang tính toán các chỉ số đánh giá...")
    print("\n" + "="*50)
    print("KẾT QUẢ ĐÁNH GIÁ")
    print("="*50)

    # Metric 1: Linter Overlap
    linter_metrics = calculate_linter_overlap(ai_flagged_lines, sonarqube_lines)
    print(f"1. Linter Overlap: {linter_metrics}")

    # Metric 2: Gemini Judge Score
    judge_metrics = get_gemini_judge_score(ai_review_full, full_code_context)
    print(f"2. Gemini Judge Score: {judge_metrics}")

    # Metric 3: Repetition Rate
    repetition_rate = calculate_repetition_rate(ai_review_full)
    print(f"3. Repetition Rate: {repetition_rate:.4f}")

    # Metric 4: Hallucination Rate
    hallucination_metrics = check_hallucination(ai_review_full, full_code_context)
    print(f"4. Hallucination Rate: {hallucination_metrics}")

    # Metric 5: Toxic Score
    if toxicity_classifier.model:
        toxic_metrics = toxicity_classifier.get_toxic_score(ai_review_full)
        print(f"5. Toxic Score: {toxic_metrics['toxic_score']:.4f}")
    
    print("\n" + "="*50)
    
    # Dọn dẹp
    bot_service_instance.close()
    bot_instance.close()


if __name__ == "__main__":
    # Thiết lập parser cho command-line arguments
    parser = argparse.ArgumentParser(description="Đánh giá chất lượng của AI Code Reviewer trên một Pull Request cụ thể.")
    parser.add_argument("repo_name", type=str, help="Tên repository trên GitHub (ví dụ: 'owner/repo').")
    parser.add_argument("pr_number", type=int, help="Số của Pull Request cần đánh giá.")
    
    args = parser.parse_args()
    
    # Gọi hàm main với các tham số từ dòng lệnh
    main(repo_name=args.repo_name, pr_number=args.pr_number)
